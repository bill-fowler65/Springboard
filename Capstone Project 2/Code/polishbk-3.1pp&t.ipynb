{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b9af03",
   "metadata": {},
   "source": [
    "# Capstone 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1dd20",
   "metadata": {},
   "source": [
    "## Polish Bankruptcy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571dad5a",
   "metadata": {},
   "source": [
    "## Pre-processing and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa3a73",
   "metadata": {},
   "source": [
    "In the pre-processing step I will impute the missing values and from the data, drop redundent high correlation variables from the dataset, complete a stratified train test split and and investigate scaling the training data.  Because of the high amount of skewed data the possibility of transforming the data may need to be done after the initial models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b0a39",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573e8927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from random import randint, choice\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7fbdfd",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46121cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 111 entries, 0 to 110\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Feature1     111 non-null    object \n",
      " 1   Feature2     111 non-null    object \n",
      " 2   Correlation  111 non-null    float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 2.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#load bankruptcy data and column key data\n",
    "bankruptcy_data = pd.read_csv('bankruptcy_data_comb.csv')\n",
    "data_columns = pd.read_csv('column_key.csv')\n",
    "\n",
    "#load high correlation dataframe\n",
    "dataCorrhigh = pd.read_csv('dataCorrhigh.csv')\n",
    "\n",
    "#display high correlation pairs dataframe\n",
    "print(dataCorrhigh.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917aaaa",
   "metadata": {},
   "source": [
    "## Impute missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178b09d",
   "metadata": {},
   "source": [
    "Based of the distribution of data and the number of outliers, I have made the decsion to imput the missing values based on the median of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa4bad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature1 Feature2  Correlation\n",
      "0        X07      X14     1.000000\n",
      "1        X56      X58     0.999976\n",
      "2        X04      X46     0.999920\n",
      "3        X20      X58     0.999894\n",
      "4        X20      X56     0.999880\n",
      "..       ...      ...          ...\n",
      "106      X07      X63     0.709315\n",
      "107      X14      X63     0.709315\n",
      "108      X44      X13     0.708622\n",
      "109      X13      X19     0.706408\n",
      "110      X63      X18     0.703221\n",
      "\n",
      "[111 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#create new dataframe by imputing missing values with the median\n",
    "bankruptcy_complete = bankruptcy_data.apply(lambda x: x.fillna(x.median()),axis=0)\n",
    "\n",
    "#display complete dataframe\n",
    "#bankruptcy_complete.info()\n",
    "\n",
    "print(dataCorrhigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2ae63",
   "metadata": {},
   "source": [
    "## Drop redundant high correlation  columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393c7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['X56', 'X04', 'X20', 'X56', 'X08', 'X19', 'X31', 'X43', 'X10', 'X53', 'X31', 'X03', 'X46', 'X04', 'X14', 'X09', 'X56', 'X20', 'X58', 'X16', 'X56', 'X44', 'X44', 'X63', 'X22', 'X12', 'X48', 'X12', 'X49', 'X43', 'X49', 'X56', 'X49', 'X11', 'X63', 'X49', 'X32', 'X33', 'X32', 'X63', 'X36', 'X03', 'X51', 'X62', 'X64', 'X64', 'X44', 'X43', 'X22', 'X11', 'X33', 'X63', 'X63', 'X49', 'X33', 'X63', 'X14', 'X30', 'X30', 'X30', 'X48', 'X35', 'X18', 'X22', 'X22', 'X33', 'X11', 'X18', 'X62', 'X43', 'X33', 'X14', 'X62', 'X62', 'X62', 'X18', 'X10', 'X25', 'X02', 'X34', 'X36', 'X14', 'X18', 'X24', 'X24', 'X06', 'X06', 'X24', 'X24', 'X24', 'X34', 'X24', 'X13', 'X13', 'X20', 'X11', 'X34', 'X35', 'X43', 'X14', 'X44', 'X13', 'X63']\n"
     ]
    }
   ],
   "source": [
    "# drop first row of correlation dataframe with correlation of 1.  Data is identical \n",
    "dataCorrhigh = dataCorrhigh.drop(dataCorrhigh.index[0]).reset_index(drop=True)\n",
    "\n",
    "#create empty final high correlation dataframe\n",
    "corr_high_final = []\n",
    "print(type(corr_high_final))\n",
    "\n",
    "# remove redundant feature X07\n",
    "dataCorrhigh = dataCorrhigh.drop(dataCorrhigh[(dataCorrhigh['Feature1'] == 'X07') | (dataCorrhigh['Feature2'] == 'X07')].index,axis = 0 ,inplace = False)\n",
    "dataCorrhigh = dataCorrhigh.reset_index(drop=True)\n",
    "\n",
    "# iterate over high correlation dataframe and use random number to determine final feture dataframe\n",
    "for x in range(len(dataCorrhigh)):\n",
    "    k = random.randint(0, 1)\n",
    "    if k == 0:\n",
    "        corr_high_final.append(dataCorrhigh['Feature1'][x])\n",
    "        \n",
    "    else:\n",
    "        corr_high_final.append(dataCorrhigh['Feature2'][x])\n",
    "   \n",
    "print(corr_high_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2997699",
   "metadata": {},
   "source": [
    "## Create final feature array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69759c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X02' 'X03' 'X04' 'X06' 'X08' 'X09' 'X10' 'X11' 'X12' 'X13' 'X14' 'X16'\n",
      " 'X18' 'X19' 'X20' 'X22' 'X24' 'X25' 'X30' 'X31' 'X32' 'X33' 'X34' 'X35'\n",
      " 'X36' 'X43' 'X44' 'X46' 'X48' 'X49' 'X51' 'X53' 'X56' 'X58' 'X62' 'X63'\n",
      " 'X64']\n"
     ]
    }
   ],
   "source": [
    "# get unique feature array\n",
    "feature_df = np.unique(corr_high_final)\n",
    "print(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f48f",
   "metadata": {},
   "source": [
    "## Remove non correlated columns from bankruptcy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec48ac76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43405 entries, 0 to 43404\n",
      "Data columns (total 39 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X02     43405 non-null  float64\n",
      " 1   X03     43405 non-null  float64\n",
      " 2   X04     43405 non-null  float64\n",
      " 3   X06     43405 non-null  float64\n",
      " 4   X08     43405 non-null  float64\n",
      " 5   X09     43405 non-null  float64\n",
      " 6   X10     43405 non-null  float64\n",
      " 7   X11     43405 non-null  float64\n",
      " 8   X12     43405 non-null  float64\n",
      " 9   X13     43405 non-null  float64\n",
      " 10  X14     43405 non-null  float64\n",
      " 11  X16     43405 non-null  float64\n",
      " 12  X18     43405 non-null  float64\n",
      " 13  X19     43405 non-null  float64\n",
      " 14  X20     43405 non-null  float64\n",
      " 15  X22     43405 non-null  float64\n",
      " 16  X24     43405 non-null  float64\n",
      " 17  X25     43405 non-null  float64\n",
      " 18  X30     43405 non-null  float64\n",
      " 19  X31     43405 non-null  float64\n",
      " 20  X32     43405 non-null  float64\n",
      " 21  X33     43405 non-null  float64\n",
      " 22  X34     43405 non-null  float64\n",
      " 23  X35     43405 non-null  float64\n",
      " 24  X36     43405 non-null  float64\n",
      " 25  X43     43405 non-null  float64\n",
      " 26  X44     43405 non-null  float64\n",
      " 27  X46     43405 non-null  float64\n",
      " 28  X48     43405 non-null  float64\n",
      " 29  X49     43405 non-null  float64\n",
      " 30  X51     43405 non-null  float64\n",
      " 31  X53     43405 non-null  float64\n",
      " 32  X56     43405 non-null  float64\n",
      " 33  X58     43405 non-null  float64\n",
      " 34  X62     43405 non-null  float64\n",
      " 35  X63     43405 non-null  float64\n",
      " 36  X64     43405 non-null  float64\n",
      " 37  Year    43405 non-null  int64  \n",
      " 38  Class   43405 non-null  int64  \n",
      "dtypes: float64(37), int64(2)\n",
      "memory usage: 12.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create new dataframe with high correlation features\n",
    "bankruptcy_data_final = bankruptcy_complete[feature_df].copy()\n",
    "\n",
    "# add back in the year and class features\n",
    "bankruptcy_data_final = pd.concat([bankruptcy_data_final,bankruptcy_complete['Year']], axis = 1)\n",
    "bankruptcy_data_final = pd.concat([bankruptcy_data_final,bankruptcy_complete['Class']], axis = 1)\n",
    "print(bankruptcy_data_final.info()) # head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e34b9",
   "metadata": {},
   "source": [
    "## Drop column variables from column key dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e1ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f64a91a",
   "metadata": {},
   "source": [
    "## Train test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b7204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X02      X03      X04       X06      X08      X09      X10  \\\n",
      "12113  1.39110 -0.83283  0.39990 -1.630900 -0.31339  0.88906 -0.43594   \n",
      "3289   0.25636  0.27021  2.05400  0.035034  2.84740  0.98773  0.72997   \n",
      "16567  0.54284 -0.12099  0.72904  0.188430  0.74268  1.00990  0.40316   \n",
      "21367  0.54860  0.37752  2.66550  0.297050  0.78826  1.12700  0.43244   \n",
      "32394  0.10553  0.60189  6.70350  0.390000  8.44050  1.16000  0.89073   \n",
      "...        ...      ...      ...       ...      ...      ...      ...   \n",
      "24299  2.15570 -0.69448  0.25470 -0.072920 -0.53611  1.14410 -1.15570   \n",
      "41350  0.43133  0.28017  1.64960  0.217130  1.25060  1.07930  0.53940   \n",
      "38703  0.55160  0.17282  1.91770  0.000000  0.81292  1.18680  0.44840   \n",
      "12352  0.15038  0.49805  5.54020 -0.000078  5.64980  0.99346  0.84962   \n",
      "24962  0.69258 -0.24260  0.54536 -0.054472  0.44388  6.12300  0.30742   \n",
      "\n",
      "            X11       X12       X13  ...       X48       X49      X51  \\\n",
      "12113 -1.068200 -0.769670 -0.104620  ... -1.855800 -0.947810  1.38780   \n",
      "3289   0.014925  0.058218  0.023540  ... -0.067718 -0.024218  0.25636   \n",
      "16567  0.013167  0.029487  0.032714  ... -0.015925 -0.011514  0.44653   \n",
      "21367  0.119670  0.527940  0.125330  ...  0.111680  0.095295  0.22667   \n",
      "32394  0.152710  1.447100  0.196260  ...  0.100640  0.100410  0.10553   \n",
      "...         ...       ...       ...  ...       ...       ...      ...   \n",
      "24299 -1.080300 -1.222200 -0.961970  ... -1.118600 -0.977650  0.93181   \n",
      "41350  0.143070  0.331700  0.092277  ...  0.102910  0.056939  0.43133   \n",
      "38703  0.137730  0.423600  0.093009  ...  0.091206  0.076851  0.18832   \n",
      "12352  0.152910  1.383600  0.194080  ...  0.096753  0.097390  0.10970   \n",
      "24962  0.051654  0.060870  0.016724  ... -0.018695 -0.003053  0.53360   \n",
      "\n",
      "           X53       X56      X58      X62      X63     X64  Year  \n",
      "12113 -0.97963 -0.124790  1.12480  258.710   1.4109  4.4000     2  \n",
      "3289   1.54190 -0.012423  1.01240   33.465  10.9070  5.9061     1  \n",
      "16567  0.59774  0.009814  0.99019  117.840   3.0973  2.0506     2  \n",
      "21367  1.09260  0.112700  0.88730   70.597   5.1702  2.9609     3  \n",
      "32394  3.04450  0.137950  0.86205   38.432   9.4973  3.4257     4  \n",
      "...        ...       ...      ...      ...      ...     ...   ...  \n",
      "24299 -1.51530 -0.919860  1.99770  297.260   1.2279  1.5002     3  \n",
      "41350  1.86960  0.073493  0.92651   87.103   4.1905  6.2648     5  \n",
      "38703  0.70188  0.106670  0.93618   57.917   6.3021  1.8577     5  \n",
      "12352  2.16600  0.134320  0.85032   40.303   9.0564  2.5327     2  \n",
      "24962  0.43360  0.007864  0.99739   31.809  11.4750  8.6363     3  \n",
      "\n",
      "[32553 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bankruptcy_data_final.drop(columns='Class'), bankruptcy_data_final.Class,\n",
    "                                                    test_size=.25  ,random_state=5, stratify=bankruptcy_data_final.Class)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf21a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32553, 38), (10852, 38))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ddb0334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32553,), (10852,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea6fbec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X02', 'X03', 'X04', 'X06', 'X08', 'X09', 'X10', 'X11', 'X12', 'X13',\n",
      "       'X14', 'X16', 'X18', 'X19', 'X20', 'X22', 'X24', 'X25', 'X30', 'X31',\n",
      "       'X32', 'X33', 'X34', 'X35', 'X36', 'X43', 'X44', 'X46', 'X48', 'X49',\n",
      "       'X51', 'X53', 'X56', 'X58', 'X62', 'X63', 'X64', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba40192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b47451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a75885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae34a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_tr_pred = clf.predict(X_train_scaled)\n",
    "y_te_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b79bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Test] Accuracy score (y_predict_test, ytestlr): 0.9517139697751567\n",
      "\n",
      "\n",
      "[Test] Accuracy score: (y_test, y_te_pred) 0.9517139697751567\n",
      "\n",
      "\n",
      "[Training] Accuracy score: (y_train, y_predict_training) 0.9518323963997174\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score (y_predict_test, ytestlr):\",accuracy_score(y_te_pred, y_test))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"[Test] Accuracy score: (y_test, y_te_pred)\",accuracy_score(y_test, y_te_pred))\n",
    "\n",
    "y_predict_training = clf.predict(X_train_scaled)\n",
    "print(\"\\n\")\n",
    "print(\"[Training] Accuracy score: (y_train, y_predict_training)\",accuracy_score(y_train, y_predict_training))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c655dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
